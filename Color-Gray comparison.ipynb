{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-03T15:25:16.777964Z",
     "iopub.status.busy": "2022-02-03T15:25:16.777297Z",
     "iopub.status.idle": "2022-02-03T15:25:22.683510Z",
     "shell.execute_reply": "2022-02-03T15:25:22.682786Z",
     "shell.execute_reply.started": "2022-02-03T15:25:16.777873Z"
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tqdm'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-ba3c128891ea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtime\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msleep\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtqdm\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tqdm'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from time import sleep\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.models import Sequential      #This allows appending layers to existing models\n",
    "from tensorflow.keras.layers import Dense           #This allows defining the characteristics of a particular layer\n",
    "from tensorflow.keras import optimizers             #This allows using whichever optimiser we want (sgd,adam,RMSprop)\n",
    "from tensorflow.keras import regularizers           #This allows using whichever regularizer we want (l1,l2,l1_l2)\n",
    "from tensorflow.keras.utils import to_categorical   #This allows using categorical cross entropy as the cost function\n",
    "#from tensorflow.keras import Conv2D\n",
    "#from tensorflow.keras import MaxPooling2D\n",
    "#from tensorflow.keras import Flatten\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from numpy import asarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-03T15:26:05.847164Z",
     "iopub.status.busy": "2022-02-03T15:26:05.846662Z",
     "iopub.status.idle": "2022-02-03T15:26:05.870738Z",
     "shell.execute_reply": "2022-02-03T15:26:05.870081Z",
     "shell.execute_reply.started": "2022-02-03T15:26:05.847129Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_path(Id,df):\n",
    "    \"\"\"Input: row number of the dataframe\n",
    "       Returns the filepath for the corresponding image\"\"\"\n",
    "    \n",
    "    #get path from dataframe\n",
    "    path2 = df.loc[Id][\"filepaths\"]\n",
    "    \n",
    "    #return the path\n",
    "    return path2\n",
    "\n",
    "def get_image(Id,df,x=224,y=224):\n",
    "    \"\"\"Returns image of a given row of the birds dataframe\"\"\"\n",
    "    #get initial path to all data\n",
    "    path1 = \"kaggle/input/inputbirds/\"\n",
    "    \n",
    "    #call fet_path function\n",
    "    path2 = get_path(Id,df)\n",
    "    \n",
    "    #read image of the path1+path2 and return it\n",
    "    return Image.open(path1+path2).resize((x,y))\n",
    "\n",
    "def get_input_NN(Id,df,gray = False):\n",
    "    \"\"\"Return a 3D matrix of image ready to be read in the CNN\"\"\"\n",
    "    \n",
    "    #call fet_image function to read image\n",
    "    im = get_image(Id,df)\n",
    "    \n",
    "    #transform iamge to RGB format\n",
    "    rgb_im = im.convert('RGB')\n",
    "    \n",
    "    if gray:\n",
    "        g_im = rgb_im.convert('L')\n",
    "        input_NN = asarray(g_im)\n",
    "                \n",
    "    else:\n",
    "    \n",
    "        #Empty zeros matrix to be filled with pixel values of the image\n",
    "        input_NN = np.zeros((3,224,224))\n",
    "\n",
    "        #fill up the matrix with RGB values at each point\n",
    "        for x in range(224):\n",
    "            for y in range(224):\n",
    "                r, g, b = rgb_im.getpixel((x,y))\n",
    "                input_NN[0,x,y] = r\n",
    "                input_NN[1,x,y] = g\n",
    "                input_NN[2,x,y] = b\n",
    "\n",
    "    #returns the 3D matrix a s a numpy array\n",
    "    return input_NN\n",
    "\n",
    "\n",
    "def show_image(Id,inputs):\n",
    "    \"\"\"Print image from Id of image in the input array\"\"\"\n",
    "    im = plt.imshow(inputs[Id].astype('uint8'))\n",
    "\n",
    "\n",
    "\n",
    "def get_class_dict():\n",
    "    \"\"\"Return dictionary of classes of each target\"\"\"\n",
    "\n",
    "    class_dict_df = pd.read_csv(\"/kaggle/input/inputbirds/class_dict.csv\")\n",
    "    class_dict = {}\n",
    "    for row in range(len(class_dict_df)):\n",
    "        class_dict[class_dict_df.iloc[row][1]] = class_dict_df.iloc[row][0]\n",
    "    return class_dict\n",
    "\n",
    "\n",
    "def CNNDefinition(fil, k_size,  Poolsize, dense, \n",
    "                  input_shape, N_categ ,  loss = 'categorical_crossentropy',  \n",
    "                  metrics = ['accuracy'], last_act = \"softmax\", lmb = 0.01, eta = 0.001,summary = True):\n",
    "    \"\"\"\n",
    "    This CNNDefinition function allows the definition of a CNN network. The Network defined can be exploited for both \n",
    "    a regression and for a classification task.\n",
    "    \n",
    "    Parameters ---\n",
    "    fil : list of the number of filters per each convolutional layer,\n",
    "    k_size : dimension of the kernels related to each convolutional layer,\n",
    "    Poolsize : dimension of the pooling layer applied after each convolutional one,\n",
    "    dense : list of dimensions of dense layers applied after the convolutional step, \n",
    "    input_shape :  dimension of the input data , \n",
    "    N_categ : number of categories in the classification task (has to be set at 1 for regression),\n",
    "    loss = 'categorical_crossentropy',  \n",
    "    metrics = ['accuracy'], \n",
    "    last_act : default = \"sigmoid\", ok for classification. Has to be changed for regression\n",
    "    \"\"\"\n",
    "    model = keras.Sequential()    \n",
    "    model.add(layers.Conv2D(filters = fil[0], kernel_size = k_size[0],\n",
    "                            padding = \"same\",\n",
    "                            activation = \"relu\",\n",
    "                            input_shape = input_shape,\n",
    "                            kernel_regularizer=regularizers.l2(lmb)\n",
    "                            ))\n",
    "    model.add(layers.MaxPooling2D(Poolsize[0]))\n",
    "#     model.add(layers.SpatialDropout2D(0.3))\n",
    "\n",
    "    for i in range(1,len(fil)):\n",
    "        model.add(layers.Conv2D(filters = fil[i], kernel_size = k_size[i],\n",
    "                                padding = \"same\", activation = \"relu\",kernel_regularizer=regularizers.l2(lmb)))\n",
    "        model.add(layers.MaxPooling2D(Poolsize[i]))\n",
    "#         model.add(layers.SpatialDropout2D(0.3))\n",
    "\n",
    "    model.add(layers.Flatten())\n",
    "    for i in range(len(dense)):\n",
    "        model.add(layers.Dense(dense[i],activation=\"relu\",kernel_regularizer=regularizers.l2(lmb)))\n",
    "\n",
    "    #model.add(layers.Dropout(0.2))\n",
    "    model.add(layers.Dense(N_categ, activation= last_act))\n",
    "    \n",
    "    if summary:\n",
    "        print(model.summary())\n",
    "\n",
    "    #default optimizer is Adam, different learning rates affect the time the network takes to converge.\n",
    "    \n",
    "    #try different alogrithms and learning rates\n",
    "    optimizer = keras.optimizers.Adam()\n",
    "#     optimizer = keras.optimizers.SGD()\n",
    "    \n",
    "    optimizer.learning_rate.assign(eta)\n",
    "\n",
    "    model.compile(\n",
    "        optimizer = optimizer, \n",
    "        loss = loss, \n",
    "        metrics = metrics\n",
    "    )\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "def Fit(model, X_train, Y_train, X_test, Y_test, pat = 100, mindelta = 0.01, batch = 64, epochs = 1200, verb = 1):\n",
    "    \n",
    "    '''\n",
    "    Fit function for fitting the model. Training and test data are specified as parameters; \n",
    "    EarlyStopping is introduced to avoid overfitting.\n",
    "    The function returns a dataframe containing the history of the training. The values of the accuracy and the different \n",
    "    epochs can be then inferred from such a returned quantity.\n",
    "    \n",
    "    Parameters ---\n",
    "    model : model to be fit,\n",
    "    X_train : train features,\n",
    "    Y_train : train targets,\n",
    "    X_test : test features,\n",
    "    Y_test : test features,\n",
    "    pat : default = 100, patience for the EarlyStopping, \n",
    "    mindelta : default = 0.01, mindelta in EarlyStopping, \n",
    "    batch : default = 64, batch size while fitting, \n",
    "    epochs : default = 1200, number of epochs for training,  \n",
    "    verb = 1):\n",
    "    '''\n",
    "\n",
    "    early_stopping = keras.callbacks.EarlyStopping(\n",
    "        patience = pat,\n",
    "        min_delta = mindelta,\n",
    "        restore_best_weights=True,\n",
    "    )\n",
    "\n",
    "    history = model.fit(\n",
    "        X_train, Y_train,\n",
    "        validation_data=(X_test, Y_test),\n",
    "        batch_size = batch,\n",
    "        epochs = epochs,\n",
    "        callbacks=[early_stopping],\n",
    "        verbose=verb, # hide the output because we have so many epochs\n",
    "    )\n",
    "    return pd.DataFrame(history.history)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen_vgg = ImageDataGenerator() \n",
    "#\n",
    "train_generator_vgg = datagen_vgg.flow_from_directory('/kaggle/input/100-bird-species/train',\n",
    "                                                      batch_size=128,\n",
    "                                                      target_size=(224,224),\n",
    "                                                      class_mode='categorical')\n",
    "#\n",
    "validation_generator_vgg = datagen_vgg.flow_from_directory('/kaggle/input/100-bird-species/valid',\n",
    "                                                           batch_size=128,\n",
    "                                                           target_size=(224,224),\n",
    "                                                           class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-01T15:16:48.465766Z",
     "iopub.status.busy": "2022-02-01T15:16:48.465503Z",
     "iopub.status.idle": "2022-02-01T15:16:57.79992Z",
     "shell.execute_reply": "2022-02-01T15:16:57.799032Z",
     "shell.execute_reply.started": "2022-02-01T15:16:48.465738Z"
    }
   },
   "outputs": [],
   "source": [
    "# birds = pd.read_csv(\"/kaggle/input/inputbirds/birds.csv\")\n",
    "# label_list = list(birds.labels.unique())\n",
    "# sub_label_list = label_list[0:100]\n",
    "# birds_100 = birds[birds[\"labels\"].isin(sub_label_list)]\n",
    "\n",
    "# train_100 = birds_100[birds_100[\"data set\"] == \"train\"]\n",
    "\n",
    "# class_dict = get_class_dict()\n",
    "# # labels = np.zeros((2987))\n",
    "# labels = np.zeros((len(train_100)))\n",
    "# for label in range(len(train_100)):\n",
    "#     labels[label] = class_dict[train_100.iloc[label][1]]\n",
    "    \n",
    "# a_file = open(\"/kaggle/input/inputbirds/inputs_56_56_100.pkl\", \"rb\")\n",
    "# inputs = pickle.load(a_file)\n",
    "# inputs = inputs/255\n",
    "\n",
    "# train_size = 0.8\n",
    "# test_size = 1 - train_size\n",
    "# X_train, X_test, Y_train, Y_test = train_test_split(inputs, labels,  train_size=train_size,\n",
    "#                                                     test_size=test_size)\n",
    "\n",
    "# Y_train = to_categorical(Y_train)\n",
    "# Y_test = to_categorical(Y_test)\n",
    "# input_shape = inputs[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-03T15:26:29.027061Z",
     "iopub.status.busy": "2022-02-03T15:26:29.026412Z",
     "iopub.status.idle": "2022-02-03T15:26:31.489793Z",
     "shell.execute_reply": "2022-02-03T15:26:31.489054Z",
     "shell.execute_reply.started": "2022-02-03T15:26:29.027023Z"
    }
   },
   "outputs": [],
   "source": [
    "birds = pd.read_csv(\"/kaggle/input/inputbirds/birds.csv\")\n",
    "label_list = list(birds.labels.unique())\n",
    "sub_label_list = label_list[0:20]\n",
    "birds_20 = birds[birds[\"labels\"].isin(sub_label_list)]\n",
    "\n",
    "train_20 = birds_20[birds_20[\"data set\"] == \"train\"]\n",
    "\n",
    "class_dict = get_class_dict()\n",
    "labels = np.zeros((len(train_20)))\n",
    "for label in range(len(train_20)):\n",
    "    labels[label] = class_dict[train_20.iloc[label][1]]\n",
    "    \n",
    "a_file = open(\"/kaggle/input/inputbirds/inputs_56_56.pkl\", \"rb\")\n",
    "inputs = pickle.load(a_file)\n",
    "inputs = inputs/255\n",
    "\n",
    "train_size = 0.8\n",
    "test_size = 1 - train_size\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(inputs, labels,  train_size=train_size,\n",
    "                                                    test_size=test_size)\n",
    "\n",
    "Y_train = to_categorical(Y_train)\n",
    "Y_test = to_categorical(Y_test)\n",
    "input_shape = inputs[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-03T15:26:38.255356Z",
     "iopub.status.busy": "2022-02-03T15:26:38.255110Z",
     "iopub.status.idle": "2022-02-03T15:26:39.508077Z",
     "shell.execute_reply": "2022-02-03T15:26:39.507364Z",
     "shell.execute_reply.started": "2022-02-03T15:26:38.255328Z"
    }
   },
   "outputs": [],
   "source": [
    "birds = pd.read_csv(\"/kaggle/input/inputbirds/birds.csv\")\n",
    "label_list = list(birds.labels.unique())\n",
    "sub_label_list = label_list[0:20]\n",
    "birds_20 = birds[birds[\"labels\"].isin(sub_label_list)]\n",
    "\n",
    "train_20 = birds_20[birds_20[\"data set\"] == \"train\"]\n",
    "\n",
    "class_dict = get_class_dict()\n",
    "labels = np.zeros((len(train_20)))\n",
    "for label in range(len(train_20)):\n",
    "    labels[label] = class_dict[train_20.iloc[label][1]]\n",
    "    \n",
    "a_file = open(\"/kaggle/input/inputbirds/inputs_56_56_gray.pkl\", \"rb\")\n",
    "inputs = pickle.load(a_file)\n",
    "inputs = inputs/255\n",
    "\n",
    "inputs_corrected = np.zeros([len(train_20),56,56,1])\n",
    "for n,image in enumerate(inputs):\n",
    "    inputs_corrected[n] = np.array([image]).T\n",
    "\n",
    "\n",
    "train_size = 0.8\n",
    "test_size = 1 - train_size\n",
    "X_train_g, X_test_g, Y_train_g, Y_test_g = train_test_split(inputs_corrected, labels,  train_size=train_size,\n",
    "                                                    test_size=test_size)\n",
    "\n",
    "Y_train_g = to_categorical(Y_train_g)\n",
    "Y_test_g = to_categorical(Y_test_g)\n",
    "input_shape_g = inputs_corrected[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-03T11:43:05.835455Z",
     "iopub.status.busy": "2022-02-03T11:43:05.834893Z",
     "iopub.status.idle": "2022-02-03T11:43:05.84317Z",
     "shell.execute_reply": "2022-02-03T11:43:05.842138Z",
     "shell.execute_reply.started": "2022-02-03T11:43:05.835404Z"
    }
   },
   "outputs": [],
   "source": [
    "len(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-02T12:08:23.207846Z",
     "iopub.status.busy": "2022-02-02T12:08:23.207544Z",
     "iopub.status.idle": "2022-02-02T12:09:46.135073Z",
     "shell.execute_reply": "2022-02-02T12:09:46.134301Z",
     "shell.execute_reply.started": "2022-02-02T12:08:23.207815Z"
    }
   },
   "outputs": [],
   "source": [
    "l_fil = [50,100] #number of filters randomly initialized -->\n",
    "l_ker = [2,4] #filters -->  size of the square filter\n",
    "l_pool = [5, 10]  #size of pooled matrix\n",
    "l_dense = []\n",
    "model_0 = CNNDefinition(l_fil, l_ker, l_pool, l_dense, X_train[0].shape, Y_train.shape[1], lmb = 0.00001, eta = 0.001)\n",
    "history_0 = Fit(model_0, X_train, Y_train, X_test, Y_test, epochs = 150)\n",
    "\n",
    "model_1 = CNNDefinition(l_fil, l_ker, l_pool, l_dense, X_train_g[0].shape, Y_train_g.shape[1], lmb = 0.00001, eta = 0.001)\n",
    "history_1 = Fit(model_1, X_train_g, Y_train_g, X_test_g, Y_test_g, epochs = 150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-02T12:13:02.760015Z",
     "iopub.status.busy": "2022-02-02T12:13:02.759765Z",
     "iopub.status.idle": "2022-02-02T12:13:03.112735Z",
     "shell.execute_reply": "2022-02-02T12:13:03.112101Z",
     "shell.execute_reply.started": "2022-02-02T12:13:02.759985Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,10))\n",
    "plt.plot(history_0.accuracy,\"--\", color = \"blue\", label=\"Train Accuracy color\")\n",
    "plt.plot(history_1.accuracy,\"--\", color =\"gray\",label=\"Train Accuracy gray\")\n",
    "plt.plot(history_0.val_accuracy, color = \"blue\",label=\"Test accuracy color\" )\n",
    "plt.plot(history_1.val_accuracy, color =\"gray\", label=\"Test accuracy gray\" )\n",
    "plt.legend(fontsize=20)\n",
    "plt.xlabel(\"Number of epochs\",fontsize=20)\n",
    "plt.ylabel(\"Accuracy\",fontsize=20)\n",
    "plt.savefig(\"graystudie.jpg\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-02T14:54:20.719076Z",
     "iopub.status.busy": "2022-02-02T14:54:20.718407Z",
     "iopub.status.idle": "2022-02-02T14:55:02.025478Z",
     "shell.execute_reply": "2022-02-02T14:55:02.024715Z",
     "shell.execute_reply.started": "2022-02-02T14:54:20.719029Z"
    }
   },
   "outputs": [],
   "source": [
    "l_fil = [50,100] #number of filters randomly initialized -->\n",
    "l_ker = [2,4] #filters -->  size of the square filter\n",
    "l_pool = [5, 10]  #size of pooled matrix\n",
    "l_dense = []\n",
    "model_0 = CNNDefinition(l_fil, l_ker, l_pool, l_dense, X_train[0].shape, Y_train.shape[1], lmb = 0.00001, eta = 0.001)\n",
    "history_0 = Fit(model_0, X_train, Y_train, X_test, Y_test, epochs = 150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-03T15:28:20.347018Z",
     "iopub.status.busy": "2022-02-03T15:28:20.346700Z",
     "iopub.status.idle": "2022-02-03T15:28:20.358198Z",
     "shell.execute_reply": "2022-02-03T15:28:20.357460Z",
     "shell.execute_reply.started": "2022-02-03T15:28:20.346986Z"
    }
   },
   "outputs": [],
   "source": [
    "def CNNDefinition_(fil, k_size,  Poolsize, dense, \n",
    "                  input_shape, N_categ ,  loss = 'categorical_crossentropy',  \n",
    "                  metrics = ['accuracy'], last_act = \"softmax\", lmb = 0.01, eta = 0.001,summary = True,drop1 = 0.2, drop2 = 0.2):\n",
    "    \"\"\"\n",
    "    This CNNDefinition function allows the definition of a CNN network. The Network defined can be exploited for both \n",
    "    a regression and for a classification task.\n",
    "    \n",
    "    Parameters ---\n",
    "    fil : list of the number of filters per each convolutional layer,\n",
    "    k_size : dimension of the kernels related to each convolutional layer,\n",
    "    Poolsize : dimension of the pooling layer applied after each convolutional one,\n",
    "    dense : list of dimensions of dense layers applied after the convolutional step, \n",
    "    input_shape :  dimension of the input data , \n",
    "    N_categ : number of categories in the classification task (has to be set at 1 for regression),\n",
    "    loss = 'categorical_crossentropy',  \n",
    "    metrics = ['accuracy'], \n",
    "    last_act : default = \"sigmoid\", ok for classification. Has to be changed for regression\n",
    "    \"\"\"\n",
    "    model = keras.Sequential()    \n",
    "    model.add(layers.Conv2D(filters = fil[0], kernel_size = k_size[0],\n",
    "                            padding = \"same\",\n",
    "                            activation = \"relu\",\n",
    "                            input_shape = input_shape,\n",
    "                            kernel_regularizer=regularizers.l2(lmb)\n",
    "                            ))\n",
    "    model.add(layers.MaxPooling2D(Poolsize[0]))\n",
    "    model.add(layers.SpatialDropout2D(drop1))\n",
    "\n",
    "    for i in range(1,len(fil)):\n",
    "        model.add(layers.Conv2D(filters = fil[i], kernel_size = k_size[i],\n",
    "                                padding = \"same\", activation = \"relu\",kernel_regularizer=regularizers.l2(lmb)))\n",
    "        model.add(layers.MaxPooling2D(Poolsize[i]))\n",
    "#         model.add(layers.SpatialDropout2D(drop))\n",
    "\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dropout(drop2))\n",
    "    for i in range(len(dense)):\n",
    "        model.add(layers.Dense(dense[i],activation=\"relu\",kernel_regularizer=regularizers.l2(lmb)))\n",
    "\n",
    "\n",
    "    model.add(layers.Dense(N_categ, activation= last_act))\n",
    "    \n",
    "    if summary:\n",
    "        print(model.summary())\n",
    "\n",
    "    #default optimizer is Adam, different learning rates affect the time the network takes to converge.\n",
    "    \n",
    "    #try different alogrithms and learning rates\n",
    "    optimizer = keras.optimizers.Adam()\n",
    "#     optimizer = keras.optimizers.SGD()\n",
    "    \n",
    "    optimizer.learning_rate.assign(eta)\n",
    "\n",
    "    model.compile(\n",
    "        optimizer = optimizer, \n",
    "        loss = loss, \n",
    "        metrics = metrics\n",
    "    )\n",
    "\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-03T15:29:54.558450Z",
     "iopub.status.busy": "2022-02-03T15:29:54.558190Z",
     "iopub.status.idle": "2022-02-03T15:29:54.562354Z",
     "shell.execute_reply": "2022-02-03T15:29:54.561554Z",
     "shell.execute_reply.started": "2022-02-03T15:29:54.558422Z"
    }
   },
   "outputs": [],
   "source": [
    "l_fil = [50,100] #number of filters randomly initialized -->\n",
    "l_ker = [2,4] #filters -->  size of the square filter\n",
    "l_pool = [5, 10]  #size of pooled matrix\n",
    "l_dense = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-03T15:35:16.112071Z",
     "iopub.status.busy": "2022-02-03T15:35:16.111322Z",
     "iopub.status.idle": "2022-02-03T15:36:34.115822Z",
     "shell.execute_reply": "2022-02-03T15:36:34.115153Z",
     "shell.execute_reply.started": "2022-02-03T15:35:16.112022Z"
    }
   },
   "outputs": [],
   "source": [
    "model_2 = CNNDefinition(l_fil, l_ker, l_pool, l_dense, X_train_g[0].shape, Y_train_g.shape[1], lmb = 0.00001, eta = 0.001)\n",
    "history_2 = Fit(model_2, X_train_g, Y_train_g, X_test_g, Y_test_g, epochs = 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-03T15:30:10.872794Z",
     "iopub.status.busy": "2022-02-03T15:30:10.872542Z",
     "iopub.status.idle": "2022-02-03T15:31:07.538728Z",
     "shell.execute_reply": "2022-02-03T15:31:07.537988Z",
     "shell.execute_reply.started": "2022-02-03T15:30:10.872766Z"
    }
   },
   "outputs": [],
   "source": [
    "model_1 = CNNDefinition_(l_fil, l_ker, l_pool, l_dense, X_train[0].shape, Y_train.shape[1], lmb = 0.00001, eta = 0.001)\n",
    "history_1 = Fit(model_1, X_train, Y_train, X_test, Y_test, epochs = 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-03T15:43:51.305300Z",
     "iopub.status.busy": "2022-02-03T15:43:51.304894Z",
     "iopub.status.idle": "2022-02-03T15:44:50.258149Z",
     "shell.execute_reply": "2022-02-03T15:44:50.257452Z",
     "shell.execute_reply.started": "2022-02-03T15:43:51.305262Z"
    }
   },
   "outputs": [],
   "source": [
    "model_3 = CNNDefinition_(l_fil, l_ker, l_pool, l_dense, X_train_g[0].shape, Y_train_g.shape[1], lmb = 0.00001, eta = 0.001)\n",
    "history_3 = Fit(model_3, X_train_g, Y_train_g, X_test_g, Y_test_g, epochs = 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-03T15:45:37.497543Z",
     "iopub.status.busy": "2022-02-03T15:45:37.497269Z",
     "iopub.status.idle": "2022-02-03T15:46:20.162754Z",
     "shell.execute_reply": "2022-02-03T15:46:20.162067Z",
     "shell.execute_reply.started": "2022-02-03T15:45:37.497511Z"
    }
   },
   "outputs": [],
   "source": [
    "model_4 = CNNDefinition(l_fil, l_ker, l_pool, l_dense, X_train[0].shape, Y_train.shape[1], lmb = 0.00001, eta = 0.001)\n",
    "history_4 = Fit(model_4, X_train, Y_train, X_test, Y_test, epochs = 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-03T15:55:32.480180Z",
     "iopub.status.busy": "2022-02-03T15:55:32.479859Z",
     "iopub.status.idle": "2022-02-03T15:55:32.901054Z",
     "shell.execute_reply": "2022-02-03T15:55:32.900325Z",
     "shell.execute_reply.started": "2022-02-03T15:55:32.480144Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,10))\n",
    "plt.plot(history_1.accuracy,\"-*\", label=\"Train Accuracy Color & Drop out\", color = \"orange\")\n",
    "plt.plot(history_4.accuracy,\"-^\", label=\"Train Accuracy Color\",  color = \"orange\")\n",
    "plt.plot(history_1.val_accuracy,\"--\", label=\"Test Accuracy Color & Drop out\",  color = \"orange\")\n",
    "plt.plot(history_4.val_accuracy,linestyle = \"dotted\", label=\"Test Accuracy Color\",  color = \"orange\")\n",
    "\n",
    "\n",
    "plt.plot(history_3.accuracy,\"-*\", label=\"Train Accuracy Gray & Drop out\", color = \"gray\")\n",
    "plt.plot(history_2.accuracy,\"-^\", label=\"Train Accuracy Gray\", color = \"gray\")\n",
    "plt.plot(history_3.val_accuracy,\"--\", label=\"Test Accuracy Gray & Drop out\", color = \"gray\")\n",
    "plt.plot(history_2.val_accuracy,linestyle = \"dotted\", label=\"Test Accuracy Gray\", color = \"gray\")\n",
    "\n",
    "\n",
    "\n",
    "plt.legend(fontsize=20)\n",
    "plt.xlabel(\"Number of epochs\",fontsize=20)\n",
    "plt.ylabel(\"Accuracy\",fontsize=20)\n",
    "plt.savefig(\"gray_studie_new.jpg\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-02T16:38:15.148089Z",
     "iopub.status.busy": "2022-02-02T16:38:15.147528Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "sns.set()\n",
    "\n",
    "l_fil = [50,100] #number of filters randomly initialized -->\n",
    "l_ker = [2,4] #filters -->  size of the square filter\n",
    "l_pool = [5, 10]  #size of pooled matrix\n",
    "l_dense = []\n",
    "lmb = 0.00001\n",
    "eta = 0.001\n",
    "\n",
    "drop1 = np.array([0.1,0.2,0.3,0.4,0.5])\n",
    "drop2 = np.array([0.1,0.2,0.3,0.4,0.5])\n",
    "\n",
    "#train_accuracy = np.zeros((len(eta_vals), len(lmbd_vals)))\n",
    "test_accuracy = np.zeros((len(drop1), len(drop2)))\n",
    "# test_accuracy = np.zeros((len(pool_size_1), len(pool_size_2)))\n",
    "\n",
    "for i in tqdm(range(len(drop1))):\n",
    "    for j in tqdm(range(len(drop2))):\n",
    "        \n",
    "#         l_ker = [[filters_size_1[i], filters_size_1[i]],[filters_size_2[j], filters_size_2[j]]]\n",
    "#         l_pool = [[pool_size_1[i],pool_size_1[i]],[pool_size_2[j],pool_size_2[j]]]\n",
    "#         print(l_pool)\n",
    "        \n",
    "#         pool1 = pool_size_1[i]\n",
    "#         pool2 = pool_size_2[j]\n",
    "#         if int((int(56/pool1)/pool2)) == 0:\n",
    "#             test_accuracy[i][j] = 0\n",
    "            \n",
    "#         else:\n",
    "        print(drop1[i], drop2[j])\n",
    "        model = CNNDefinition_(l_fil, l_ker,l_pool, l_dense, X_train[0].shape, Y_train.shape[1],lmb = lmb, eta = eta, summary = False, drop1 = drop1[i], drop2 =drop2[j])\n",
    "        history = Fit(model, X_train, Y_train, X_test, Y_test, epochs = 100, verb = 0)\n",
    "        print(max(history.val_accuracy))\n",
    "        test_accuracy[i][j] = max(history.val_accuracy)\n",
    "\n",
    "        \n",
    "# fig, ax = plt.subplots(figsize = (10, 10))\n",
    "# sns.heatmap(train_accuracy, annot=True, ax=ax, cmap=\"viridis\")\n",
    "# ax.set_title(\"Training Accuracy\")\n",
    "# ax.set_ylabel(\"$\\eta$\")\n",
    "# ax.set_xlabel(\"$\\lambda$\")\n",
    "# plt.show()\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (10, 10))\n",
    "sns.heatmap(test_accuracy, annot=True, ax=ax, cmap=\"viridis\",xticklabels=drop2, yticklabels=drop1)\n",
    "ax.set_title(\"Test Accuracy\")\n",
    "# ax.set_xlabel(\"2nd pool size\")\n",
    "# ax.set_ylabel(\"1st pool size\")\n",
    "ax.set_ylabel(\"drop after 1st pooling\")\n",
    "ax.set_xlabel(\"drop after flatten layer\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-02T16:09:06.107483Z",
     "iopub.status.busy": "2022-02-02T16:09:06.106533Z",
     "iopub.status.idle": "2022-02-02T16:09:06.231394Z",
     "shell.execute_reply": "2022-02-02T16:09:06.22962Z",
     "shell.execute_reply.started": "2022-02-02T16:09:06.107369Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (10, 10))\n",
    "sns.heatmap(test_accuracy, annot=True, ax=ax, cmap=\"viridis\",xticklabels=drop2, yticklabels=drop1)\n",
    "ax.set_title(\"Test Accuracy\")\n",
    "# ax.set_xlabel(\"2nd pool size\")\n",
    "# ax.set_ylabel(\"1st pool size\")\n",
    "ax.set_ylabel(\"drop after 1st pooling\")\n",
    "ax.set_xlabel(\"drop after flatten layer\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-02T12:00:20.750015Z",
     "iopub.status.busy": "2022-02-02T12:00:20.749753Z",
     "iopub.status.idle": "2022-02-02T12:01:02.422633Z",
     "shell.execute_reply": "2022-02-02T12:01:02.421951Z",
     "shell.execute_reply.started": "2022-02-02T12:00:20.749985Z"
    }
   },
   "outputs": [],
   "source": [
    "l_fil = [50,100] #number of filters randomly initialized -->\n",
    "l_ker = [2,4] #filters -->  size of the square filter\n",
    "l_pool = [5, 10]  #size of pooled matrix\n",
    "l_dense = []\n",
    "model = CNNDefinition(l_fil, l_ker, l_pool, l_dense, X_train[0].shape, Y_train.shape[1],lmb = 0.00001, eta = 0.001)\n",
    "history_gray = Fit(model, X_train, Y_train, X_test, Y_test, epochs = 150)\n",
    "plt.plot(history_gray.accuracy,\"--\")\n",
    "plt.plot(history_gray.val_accuracy,\"-\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
